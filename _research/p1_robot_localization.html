---
title: "Indoor Human Localization: A cooperative localization scheme using robot-smartphone collaboration (past project)"
excerpt: "Overview: Smartphone-based human indoor localization was previously implemented using wireless sensor networks at the cost of sensing infrastructure deployment. Motivated by the increasing research attention on location-aware human-robot interaction, this project studies a robot-assisted human indoor localization scheme using acoustic ranging between a self-localized mobile robot and smartphones from human users. Data from the low-cost Kinect vision sensor are fused with smartphone-based acoustic ranging, and an extended Kalman filter based localization algorithm is developed for real-time dynamic position estimation and tracking. Real robot-smartphone experiments are performed, and performances are evaluated in various indoor environments under different environmental noises and with different human walking speed. Compared with existing indoor smartphone localization methods, the proposed system does not rely on wireless sensing infrastructure, and has comparable localization accuracy with increased flexibility and scalability due to the mobility of the robot.  <br/><img src='/images/robot_localization_overview.png'>"
collection: portfolio
---
<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <title>Multi-Robot Trajectory Optimization</title>
  <style>
    /* Container */
    .content {
      max-width: 900px;
      margin: 0 auto;
      padding: 20px;
      font-family: Arial, sans-serif;
      line-height: 1.6;
      color: #333;
    }
    
    /* Section headings */
    h2 {
      font-size: 1.5rem;
      margin-top: 2rem;
      margin-bottom: 1rem;
      border-bottom: 2px solid #ddd;
      padding-bottom: 0.5rem;
    }
    
    /* Figure grid */
    .figure-grid {
      display: grid;
      grid-template-columns: repeat(auto-fit, minmax(250px, 1fr));
      gap: 20px;
      margin: 1rem 0 2rem;
    }
    
    figure {
      margin: 0;
      text-align: center;
    }
    
    figure img {
      max-width: 100%;
      height: auto;
      border-radius: 8px;
      box-shadow: 0 2px 6px rgba(0,0,0,0.1);
    }
    
    figcaption {
      margin-top: 0.5rem;
      font-size: 0.9rem;
      color: #666;
    }
    
    /* List styling */
    .approach-list {
      margin: 0 0 1.5rem 1.2rem;
    }
    .approach-list li {
      margin-bottom: 0.8rem;
    }
    
    /* Citation style */
    .citation {
      font-size: 0.85rem;
      color: #999;
      margin-left: 0.3rem;
    }
  </style>
</head>
<body>
  <div class="content">
     <figure>
         <img src="/images/robot_localization_system.bmp" alt="Stochastic skill prediction 2">
         <figcaption>An overview of the robot-assisted human indoor localization system.</figcaption>
     </figure>
    
          
    <h2>Publications:</h2>
    <ul class="references-list">
      <li>[1] Jiang, C., Fahad, M., Guo, Y., & Chen, Y. (2018). Robot-assisted smartphone localization for human indoor tracking. Robotics and Autonomous Systems, 106, pp. 82-94.</li>
      <li>[2] Jiang, C., Fahad, M., Guo, Y., Yang, J., & Chen, Y. (2014). Robot-assisted human indoor localization using the Kinect sensor and smartphones. In 2014 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS), pp. 4083-4089</li>
    </ul>
   
  </div>
</body>
</html>
